{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa541644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from google.colab import drive\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8dd965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montar Drive (solo en notebook)\n",
    "from google.colab import drive; drive.mount('/content/drive')\n",
    "\n",
    "# Asegurar imports del paquete (elige una de estas dos lÃ­neas)\n",
    "#%pip install -e /content/mmshap_medclip\n",
    "import sys; sys.path.append(\"/content/mmshap_medclip\")\n",
    "\n",
    "from mmshap_medclip.io_utils import load_config\n",
    "from mmshap_medclip.devices import get_device\n",
    "from mmshap_medclip.registry import build_dataset, build_model\n",
    "\n",
    "cfg = load_config(\"/content/mmshap_medclip/configs/roco_isa_pubmedclip.yaml\")\n",
    "device  = get_device()  # o get_device(prefer_cuda=True)\n",
    "\n",
    "dataset = build_dataset(cfg[\"dataset\"])\n",
    "model   = build_model(cfg[\"model\"], device=device)   # CLIPWrapper\n",
    "\n",
    "muestra  = 357\n",
    "sample   = dataset[muestra]\n",
    "image    = sample[\"image\"]     # PIL.Image\n",
    "caption  = sample[\"text\"]      # str\n",
    "processor = model.processor\n",
    "tokenizer = model.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62329b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmshap_medclip.tasks.utils import prepare_batch\n",
    "\n",
    "inputs, logits = prepare_batch(\n",
    "    model_wrapper=model,\n",
    "    texts=[caption],\n",
    "    images=[image],\n",
    "    device=device,\n",
    "    debug_tokens=True,   # ponlo False cuando ya no necesites inspecciÃ³n\n",
    "    amp_if_cuda=True\n",
    ")\n",
    "model_prediction = float(logits[0, 0])\n",
    "print(\"ðŸ”® logits_per_image[0,0]:\", model_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f1566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmshap_medclip.tasks.utils import compute_text_token_lengths, make_image_token_ids\n",
    "\n",
    "# 1) Longitudes reales de texto (sin PAD)\n",
    "nb_text_tokens_tensor, nb_text_tokens = compute_text_token_lengths(inputs, tokenizer)\n",
    "print(\"Tokens por texto (sin PAD):\", nb_text_tokens)\n",
    "\n",
    "# 2) IDs de parches de imagen\n",
    "image_token_ids_expanded, imginfo = make_image_token_ids(inputs, model, debug=True)\n",
    "print(\"Forma image_token_ids_expanded:\", tuple(image_token_ids_expanded.shape))  # (B, N)\n",
    "print(\"Info imagen:\", imginfo)  # {'patch_size':..., 'grid_h':..., 'grid_w':..., 'num_patches':...}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9f67bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mmshap_medclip.tasks.utils import (\n",
    "    compute_text_token_lengths, make_image_token_ids, concat_text_image_tokens\n",
    ")\n",
    "from mmshap_medclip.shap_tools.masker import build_masker\n",
    "from mmshap_medclip.shap_tools.predictor import Predictor\n",
    "\n",
    "# 1) Longitudes reales de texto\n",
    "nb_text_tokens_tensor, nb_text_tokens = compute_text_token_lengths(inputs, tokenizer)\n",
    "\n",
    "# 2) IDs de parches e input para SHAP\n",
    "image_token_ids_expanded, imginfo = make_image_token_ids(inputs, model, debug=False)\n",
    "X_clean, seq_len = concat_text_image_tokens(inputs, image_token_ids_expanded, device=device)\n",
    "\n",
    "# 3) Masker (preserva BOS/EOS)\n",
    "masker = build_masker(nb_text_tokens_tensor, tokenizer=tokenizer)\n",
    "\n",
    "# 4) Predictor (usa el mismo device del modelo)\n",
    "predict_fn = Predictor(\n",
    "    model_wrapper=model,\n",
    "    base_inputs=inputs,                       # dict del processor (ya en device)\n",
    "    patch_size=imginfo[\"patch_size\"],         # o None para inferir\n",
    "    device=device,\n",
    "    use_amp=True\n",
    ")\n",
    "\n",
    "# 5) Explainer SHAP (SHAP suele mandar x en CPU â†’ no pasa nada)\n",
    "explainer = shap.Explainer(predict_fn, masker, silent=True)\n",
    "shap_values = explainer(X_clean.cpu())        # devuelve valores para [texto|parches]\n",
    "\n",
    "print(\"SHAP values shape:\", shap_values.values.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a27aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmshap_medclip.metrics import compute_mm_score, compute_iscore\n",
    "\n",
    "# Para el primer ejemplo del batch (i=0)\n",
    "tscore, word_shap = compute_mm_score(\n",
    "    shap_values=shap_values,\n",
    "    tokenizer=tokenizer,\n",
    "    inputs=inputs,\n",
    "    i=0\n",
    ")\n",
    "iscore = compute_iscore(shap_values, inputs, i=0)\n",
    "\n",
    "print(f\"TScore: {tscore:.2%} | IScore: {iscore:.2%}\")\n",
    "for w, s in word_shap.items():\n",
    "    print(f\"{w:>15s}: {s:+.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d09722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmshap_medclip.vis.heatmaps import plot_text_image_heatmaps\n",
    "\n",
    "# texts = lista de captions del batch\n",
    "texts = [caption]  # si B=1\n",
    "images = image     # PIL o lista de PILs\n",
    "\n",
    "# mm_scores ya lo calculaste con compute_mm_score para cada i del batch:\n",
    "# mm_scores = [(tscore_i, word_shap_i), ...]\n",
    "plot_text_image_heatmaps(\n",
    "    shap_values=shap_values,\n",
    "    inputs=inputs,\n",
    "    tokenizer=tokenizer,\n",
    "    images=images,\n",
    "    texts=texts,\n",
    "    mm_scores=mm_scores,\n",
    "    model_wrapper=model,     # CLIPWrapper\n",
    "    cmap_name=\"RdYlBu_r\",\n",
    "    alpha_img=0.60,\n",
    "    return_fig=False\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
