# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.17.3
#   kernelspec:
#     display_name: Python 3
#     name: python3
# ---

# %% [markdown]
# # üìä An√°lisis de Resultados Batch SHAP
#
# Este notebook analiza los resultados del an√°lisis batch de SHAP para los 4 modelos CLIP m√©dicos.
# Genera estad√≠sticas descriptivas, gr√°ficas comparativas, m√©tricas de balance multimodal,
# an√°lisis estad√≠sticos inferenciales y visualizaciones para presentaci√≥n.
#
# **Modelos analizados:**
# - PubMedCLIP
# - BioMedCLIP
# - RCLIP
# - WhyXRayCLIP
#
# ---

# %% [markdown]
# ## üì¶ Configuraci√≥n inicial

# %%
import os
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import kruskal, wilcoxon, shapiro
import warnings
warnings.filterwarnings('ignore')

# Configurar estilo de gr√°ficas
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 11
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['xtick.labelsize'] = 10
plt.rcParams['ytick.labelsize'] = 10
plt.rcParams['legend.fontsize'] = 10

# üìå Configuraci√≥n - Asegurar que estamos en el directorio correcto
try:
    # En scripts Python
    PROJECT_ROOT = Path(__file__).parent.parent
except NameError:
    # En notebooks de Jupyter
    PROJECT_ROOT = Path.cwd()
    # Si estamos en experiments/, subir un nivel
    if PROJECT_ROOT.name == "experiments":
        PROJECT_ROOT = PROJECT_ROOT.parent

os.chdir(PROJECT_ROOT)
print(f"üìÇ Directorio de trabajo: {PROJECT_ROOT}")

# %% [markdown]
# ## üìÅ Configuraci√≥n de rutas
#
# **‚ö†Ô∏è IMPORTANTE:** Cambia la ruta del CSV aqu√≠ seg√∫n necesites

# %%
# üéØ CONFIGURACI√ìN: Cambia esta ruta seg√∫n el CSV que quieras analizar
CSV_PATH = "outputs/batch_shap_results.csv"  # Ruta relativa al directorio ra√≠z
OUTPUT_DIR = "outputs/analysis"  # Directorio donde guardar gr√°ficas y reportes

# Crear directorio de salida si no existe
Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)

print(f"üìÇ CSV a analizar: {CSV_PATH}")
print(f"üìÇ Directorio de salida: {OUTPUT_DIR}")

# %% [markdown]
# ## üìä Carga de datos

# %%
# Cargar CSV
if not Path(CSV_PATH).exists():
    raise FileNotFoundError(f"‚ùå No se encontr√≥ el archivo: {CSV_PATH}")

df = pd.read_csv(CSV_PATH)
print(f"‚úÖ CSV cargado exitosamente")
print(f"üìä Total de muestras: {len(df)}")
print(f"üìã Columnas: {list(df.columns)}")

# Mostrar primeras filas
print("\nüìã Primeras 5 filas del dataset:")
print(df.head())

# %% [markdown]
# ## üîß Preparaci√≥n de datos

# %%
# Extraer nombres de modelos de las columnas
model_names = []
for col in df.columns:
    if col.startswith('Iscore_'):
        model_name = col.replace('Iscore_', '')
        model_names.append(model_name)

print(f"ü§ñ Modelos encontrados: {model_names}")

# Crear diccionario con datos por modelo (filtrando NaN)
models_data = {}
for model_name in model_names:
    iscore_raw = df[f'Iscore_{model_name}'].values
    tscore_raw = df[f'Tscore_{model_name}'].values
    logit_raw = df[f'Logit_{model_name}'].values
    
    # Filtrar NaN y crear m√°scara de valores v√°lidos
    valid_mask = ~(np.isnan(iscore_raw) | np.isnan(tscore_raw) | np.isnan(logit_raw))
    
    models_data[model_name] = {
        'iscore': iscore_raw[valid_mask],
        'tscore': tscore_raw[valid_mask],
        'logit': logit_raw[valid_mask],
        'valid_count': np.sum(valid_mask),
        'total_count': len(iscore_raw)
    }
    
    if np.sum(valid_mask) < len(iscore_raw):
        print(f"‚ö†Ô∏è  {model_name}: {len(iscore_raw) - np.sum(valid_mask)} valores NaN encontrados y filtrados")

# %% [markdown]
# ## 1Ô∏è‚É£ Estad√≠sticas Descriptivas por Modelo

# %%
print("="*80)
print("üìä ESTAD√çSTICAS DESCRIPTIVAS POR MODELO")
print("="*80)

# Crear DataFrame con estad√≠sticas
stats_list = []

for model_name in model_names:
    iscore = models_data[model_name]['iscore']
    tscore = models_data[model_name]['tscore']
    logit = models_data[model_name]['logit']
    valid_count = models_data[model_name]['valid_count']
    
    # Usar funciones que manejan NaN correctamente
    if len(iscore) > 0:
        stats_list.append({
            'Modelo': model_name,
            'M√©trica': 'IScore',
            'Media': np.nanmean(iscore),
            'Mediana': np.nanmedian(iscore),
            'Desv. Est.': np.nanstd(iscore),
            'M√≠nimo': np.nanmin(iscore),
            'M√°ximo': np.nanmax(iscore),
            'Q25': np.nanpercentile(iscore, 25),
            'Q75': np.nanpercentile(iscore, 75),
            'CV (%)': (np.nanstd(iscore) / np.nanmean(iscore)) * 100 if np.nanmean(iscore) > 0 else 0,
            'N v√°lidos': valid_count
        })
        
        stats_list.append({
            'Modelo': model_name,
            'M√©trica': 'TScore',
            'Media': np.nanmean(tscore),
            'Mediana': np.nanmedian(tscore),
            'Desv. Est.': np.nanstd(tscore),
            'M√≠nimo': np.nanmin(tscore),
            'M√°ximo': np.nanmax(tscore),
            'Q25': np.nanpercentile(tscore, 25),
            'Q75': np.nanpercentile(tscore, 75),
            'CV (%)': (np.nanstd(tscore) / np.nanmean(tscore)) * 100 if np.nanmean(tscore) > 0 else 0,
            'N v√°lidos': valid_count
        })
        
        stats_list.append({
            'Modelo': model_name,
            'M√©trica': 'Logit',
            'Media': np.nanmean(logit),
            'Mediana': np.nanmedian(logit),
            'Desv. Est.': np.nanstd(logit),
            'M√≠nimo': np.nanmin(logit),
            'M√°ximo': np.nanmax(logit),
            'Q25': np.nanpercentile(logit, 25),
            'Q75': np.nanpercentile(logit, 75),
            'CV (%)': (np.nanstd(logit) / np.nanmean(logit)) * 100 if np.nanmean(logit) > 0 else 0,
            'N v√°lidos': valid_count
        })
    else:
        print(f"‚ö†Ô∏è  {model_name}: No hay datos v√°lidos para calcular estad√≠sticas")

df_stats = pd.DataFrame(stats_list)

# Mostrar tabla formateada
print("\nüìã Tabla de estad√≠sticas descriptivas:")
print(df_stats.to_string(index=False))

# Guardar en CSV
stats_path = Path(OUTPUT_DIR) / "estadisticas_descriptivas.csv"
df_stats.to_csv(stats_path, index=False)
print(f"\nüíæ Estad√≠sticas guardadas en: {stats_path}")

# %% [markdown]
# ## 2Ô∏è‚É£ Gr√°ficas Comparativas

# %% [markdown]
# ### 2.1 Boxplots de IScore y TScore por Modelo

# %%
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Preparar datos para boxplot
iscore_data = [models_data[model]['iscore'] for model in model_names]
tscore_data = [models_data[model]['tscore'] for model in model_names]

# Boxplot IScore
bp1 = axes[0].boxplot(iscore_data, labels=model_names, patch_artist=True)
axes[0].axhline(y=0.5, color='r', linestyle='--', linewidth=2, label='Balance ideal (50%)')
axes[0].set_title('Distribuci√≥n de IScore por Modelo', fontsize=14, fontweight='bold')
axes[0].set_ylabel('IScore', fontsize=12)
axes[0].set_xlabel('Modelo', fontsize=12)
axes[0].grid(True, alpha=0.3)
axes[0].legend()
axes[0].set_ylim(0, 1)

# Colorear boxes
colors = plt.cm.Set3(np.linspace(0, 1, len(bp1['boxes'])))
for patch, color in zip(bp1['boxes'], colors):
    patch.set_facecolor(color)
    patch.set_alpha(0.7)

# Boxplot TScore
bp2 = axes[1].boxplot(tscore_data, labels=model_names, patch_artist=True)
axes[1].axhline(y=0.5, color='r', linestyle='--', linewidth=2, label='Balance ideal (50%)')
axes[1].set_title('Distribuci√≥n de TScore por Modelo', fontsize=14, fontweight='bold')
axes[1].set_ylabel('TScore', fontsize=12)
axes[1].set_xlabel('Modelo', fontsize=12)
axes[1].grid(True, alpha=0.3)
axes[1].legend()
axes[1].set_ylim(0, 1)

# Colorear boxes
for patch, color in zip(bp2['boxes'], colors):
    patch.set_facecolor(color)
    patch.set_alpha(0.7)

plt.tight_layout()
boxplot_path = Path(OUTPUT_DIR) / "boxplots_iscore_tscore.png"
plt.savefig(boxplot_path, dpi=300, bbox_inches='tight')
print(f"üíæ Gr√°fica guardada en: {boxplot_path}")
plt.show()

# %% [markdown]
# ### 2.2 Violin Plots de IScore y TScore

# %%
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Preparar datos en formato largo para seaborn
iscore_df = pd.DataFrame({
    'Modelo': np.repeat(model_names, [len(d) for d in iscore_data]),
    'IScore': np.concatenate(iscore_data)
})

tscore_df = pd.DataFrame({
    'Modelo': np.repeat(model_names, [len(d) for d in tscore_data]),
    'TScore': np.concatenate(tscore_data)
})

# Violin plot IScore
sns.violinplot(data=iscore_df, x='Modelo', y='IScore', ax=axes[0], inner='box')
axes[0].axhline(y=0.5, color='r', linestyle='--', linewidth=2, label='Balance ideal (50%)')
axes[0].set_title('Distribuci√≥n de IScore por Modelo (Violin Plot)', fontsize=14, fontweight='bold')
axes[0].set_ylabel('IScore', fontsize=12)
axes[0].set_xlabel('Modelo', fontsize=12)
axes[0].grid(True, alpha=0.3)
axes[0].legend()
axes[0].set_ylim(0, 1)

# Violin plot TScore
sns.violinplot(data=tscore_df, x='Modelo', y='TScore', ax=axes[1], inner='box')
axes[1].axhline(y=0.5, color='r', linestyle='--', linewidth=2, label='Balance ideal (50%)')
axes[1].set_title('Distribuci√≥n de TScore por Modelo (Violin Plot)', fontsize=14, fontweight='bold')
axes[1].set_ylabel('TScore', fontsize=12)
axes[1].set_xlabel('Modelo', fontsize=12)
axes[1].grid(True, alpha=0.3)
axes[1].legend()
axes[1].set_ylim(0, 1)

plt.tight_layout()
violin_path = Path(OUTPUT_DIR) / "violinplots_iscore_tscore.png"
plt.savefig(violin_path, dpi=300, bbox_inches='tight')
print(f"üíæ Gr√°fica guardada en: {violin_path}")
plt.show()

# %% [markdown]
# ### 2.3 Scatter Plot: IScore vs TScore

# %%
fig, axes = plt.subplots(2, 2, figsize=(16, 14))
axes = axes.flatten()

for idx, model_name in enumerate(model_names):
    iscore = models_data[model_name]['iscore']
    tscore = models_data[model_name]['tscore']
    
    axes[idx].scatter(iscore, tscore, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)
    axes[idx].plot([0, 1], [1, 0], 'r--', linewidth=2, label='Balance ideal (IScore + TScore = 1)')
    axes[idx].axhline(y=0.5, color='gray', linestyle=':', alpha=0.5)
    axes[idx].axvline(x=0.5, color='gray', linestyle=':', alpha=0.5)
    axes[idx].set_xlabel('IScore', fontsize=12)
    axes[idx].set_ylabel('TScore', fontsize=12)
    axes[idx].set_title(f'{model_name}\nIScore vs TScore', fontsize=13, fontweight='bold')
    axes[idx].grid(True, alpha=0.3)
    axes[idx].legend()
    axes[idx].set_xlim(0, 1)
    axes[idx].set_ylim(0, 1)
    axes[idx].set_aspect('equal')

plt.suptitle('Relaci√≥n IScore vs TScore por Modelo', fontsize=16, fontweight='bold', y=0.995)
plt.tight_layout()
scatter_path = Path(OUTPUT_DIR) / "scatter_iscore_vs_tscore.png"
plt.savefig(scatter_path, dpi=300, bbox_inches='tight')
print(f"üíæ Gr√°fica guardada en: {scatter_path}")
plt.show()

# %% [markdown]
# ### 2.4 Heatmap de Correlaciones entre Modelos

# %%
# Calcular matriz de correlaci√≥n de IScores entre modelos
iscore_matrix = np.array([models_data[model]['iscore'] for model in model_names])
correlation_matrix = np.corrcoef(iscore_matrix)

fig, ax = plt.subplots(figsize=(10, 8))
sns.heatmap(
    correlation_matrix,
    annot=True,
    fmt='.3f',
    cmap='coolwarm',
    center=0,
    square=True,
    xticklabels=model_names,
    yticklabels=model_names,
    cbar_kws={'label': 'Coeficiente de Correlaci√≥n'},
    linewidths=0.5,
    linecolor='black'
)
ax.set_title('Matriz de Correlaci√≥n de IScores entre Modelos', fontsize=14, fontweight='bold', pad=20)
plt.tight_layout()
corr_path = Path(OUTPUT_DIR) / "heatmap_correlaciones.png"
plt.savefig(corr_path, dpi=300, bbox_inches='tight')
print(f"üíæ Gr√°fica guardada en: {corr_path}")
plt.show()

# %% [markdown]
# ## 3Ô∏è‚É£ M√©tricas de Balance Multimodal

# %%
print("="*80)
print("üéØ M√âTRICAS DE BALANCE MULTIMODAL")
print("="*80)

# Calcular m√©tricas de balance para cada modelo
balance_metrics = []

for model_name in model_names:
    iscore = models_data[model_name]['iscore']
    tscore = models_data[model_name]['tscore']
    
    # Balance Score: 1 - |IScore - 0.5| (m√°s cercano a 1 = m√°s balanceado)
    balance_score = 1 - np.abs(iscore - 0.5)
    
    # Desviaci√≥n del balance: |IScore - TScore|
    balance_deviation = np.abs(iscore - tscore)
    
    # Ratio IScore/TScore (ideal = 1.0)
    ratio = iscore / (tscore + 1e-10)  # Evitar divisi√≥n por cero
    
    # Porcentaje de muestras "balanceadas" (dentro de ¬±10% de 50/50)
    balanced_samples = np.sum(np.abs(iscore - 0.5) <= 0.1)
    balanced_percentage = (balanced_samples / len(iscore)) * 100
    
    balance_metrics.append({
        'Modelo': model_name,
        'Balance Score (Media)': np.mean(balance_score),
        'Balance Score (Mediana)': np.median(balance_score),
        'Desviaci√≥n Balance (Media)': np.mean(balance_deviation),
        'Ratio IScore/TScore (Media)': np.mean(ratio),
        'Muestras Balanceadas (%)': balanced_percentage,
        'Muestras Balanceadas (N)': balanced_samples,
        'Total Muestras': len(iscore)
    })

df_balance = pd.DataFrame(balance_metrics)

# Ordenar por Balance Score (mayor a menor)
df_balance = df_balance.sort_values('Balance Score (Media)', ascending=False)

print("\nüìã M√©tricas de Balance Multimodal:")
print(df_balance.to_string(index=False))

# Guardar en CSV
balance_path = Path(OUTPUT_DIR) / "metricas_balance_multimodal.csv"
df_balance.to_csv(balance_path, index=False)
print(f"\nüíæ M√©tricas guardadas en: {balance_path}")

# Visualizaci√≥n de Balance Score
fig, ax = plt.subplots(figsize=(12, 6))
x_pos = np.arange(len(model_names))
bars = ax.barh(x_pos, df_balance['Balance Score (Media)'], color=colors[:len(model_names)])
ax.set_yticks(x_pos)
ax.set_yticklabels(df_balance['Modelo'])
ax.set_xlabel('Balance Score (Media)', fontsize=12)
ax.set_title('Balance Multimodal por Modelo\n(Mayor = M√°s Balanceado, Ideal = 1.0)', 
              fontsize=14, fontweight='bold')
ax.axvline(x=1.0, color='r', linestyle='--', linewidth=2, label='Balance perfecto')
ax.grid(True, alpha=0.3, axis='x')
ax.legend()

# Agregar valores en las barras
for i, (bar, value) in enumerate(zip(bars, df_balance['Balance Score (Media)'])):
    ax.text(value + 0.01, i, f'{value:.3f}', va='center', fontweight='bold')

plt.tight_layout()
balance_viz_path = Path(OUTPUT_DIR) / "balance_score_comparison.png"
plt.savefig(balance_viz_path, dpi=300, bbox_inches='tight')
print(f"üíæ Gr√°fica guardada en: {balance_viz_path}")
plt.show()

# %% [markdown]
# ## 4Ô∏è‚É£ An√°lisis Estad√≠sticos Inferenciales

# %%
print("="*80)
print("üìà AN√ÅLISIS ESTAD√çSTICOS INFERENCIALES")
print("="*80)

# 4.1 Test de Normalidad (Shapiro-Wilk)
print("\nüîç 4.1 Test de Normalidad (Shapiro-Wilk):")
print("-" * 80)
normality_results = []

for model_name in model_names:
    iscore = models_data[model_name]['iscore']
    tscore = models_data[model_name]['tscore']
    
    # Test para IScore
    stat_iscore, p_iscore = shapiro(iscore)
    # Test para TScore
    stat_tscore, p_tscore = shapiro(tscore)
    
    normality_results.append({
        'Modelo': model_name,
        'IScore - Estad√≠stico': stat_iscore,
        'IScore - p-value': p_iscore,
        'IScore - Normal?': 'S√≠' if p_iscore > 0.05 else 'No',
        'TScore - Estad√≠stico': stat_tscore,
        'TScore - p-value': p_tscore,
        'TScore - Normal?': 'S√≠' if p_tscore > 0.05 else 'No'
    })

df_normality = pd.DataFrame(normality_results)
print(df_normality.to_string(index=False))

# 4.2 Test de Kruskal-Wallis (comparaci√≥n entre modelos)
print("\nüîç 4.2 Test de Kruskal-Wallis (Comparaci√≥n de IScores entre modelos):")
print("-" * 80)
iscore_groups = [models_data[model]['iscore'] for model in model_names]
h_stat, p_value = kruskal(*iscore_groups)
print(f"Estad√≠stico H: {h_stat:.4f}")
print(f"p-value: {p_value:.6f}")
print(f"¬øHay diferencias significativas? {'S√≠' if p_value < 0.05 else 'No'} (Œ±=0.05)")

# 4.3 Comparaciones pareadas (Wilcoxon)
print("\nüîç 4.3 Comparaciones Pareadas (Wilcoxon):")
print("-" * 80)
pairwise_results = []

for i, model1 in enumerate(model_names):
    for j, model2 in enumerate(model_names):
        if i < j:
            iscore1 = models_data[model1]['iscore']
            iscore2 = models_data[model2]['iscore']
            
            # Asegurar que tienen la misma longitud
            min_len = min(len(iscore1), len(iscore2))
            stat, p_val = wilcoxon(iscore1[:min_len], iscore2[:min_len])
            
            pairwise_results.append({
                'Modelo 1': model1,
                'Modelo 2': model2,
                'Estad√≠stico': stat,
                'p-value': p_val,
                'Significativo?': 'S√≠' if p_val < 0.05 else 'No'
            })

df_pairwise = pd.DataFrame(pairwise_results)
print(df_pairwise.to_string(index=False))

# Guardar resultados
stats_inf_path = Path(OUTPUT_DIR) / "analisis_estadisticos_inferenciales.csv"
df_pairwise.to_csv(stats_inf_path, index=False)
print(f"\nüíæ Resultados guardados en: {stats_inf_path}")

# %% [markdown]
# ## 5Ô∏è‚É£ An√°lisis de Relaci√≥n con Caption Length

# %%
print("="*80)
print("üìè AN√ÅLISIS DE RELACI√ìN CON CAPTION LENGTH")
print("="*80)

caption_lengths = df['caption_length'].values

# Calcular correlaciones
correlations = []
for model_name in model_names:
    iscore = models_data[model_name]['iscore']
    tscore = models_data[model_name]['tscore']
    
    # Correlaci√≥n de Pearson
    corr_iscore, p_iscore = stats.pearsonr(caption_lengths, iscore)
    corr_tscore, p_tscore = stats.pearsonr(caption_lengths, tscore)
    
    correlations.append({
        'Modelo': model_name,
        'Correlaci√≥n IScore-Caption': corr_iscore,
        'p-value IScore': p_iscore,
        'Significativa IScore?': 'S√≠' if p_iscore < 0.05 else 'No',
        'Correlaci√≥n TScore-Caption': corr_tscore,
        'p-value TScore': p_tscore,
        'Significativa TScore?': 'S√≠' if p_tscore < 0.05 else 'No'
    })

df_correlations = pd.DataFrame(correlations)
print("\nüìã Correlaciones con Caption Length:")
print(df_correlations.to_string(index=False))

# Guardar
corr_caption_path = Path(OUTPUT_DIR) / "correlaciones_caption_length.csv"
df_correlations.to_csv(corr_caption_path, index=False)
print(f"\nüíæ Correlaciones guardadas en: {corr_caption_path}")

# Visualizaci√≥n: Scatter plots
fig, axes = plt.subplots(2, 2, figsize=(16, 14))
axes = axes.flatten()

for idx, model_name in enumerate(model_names):
    iscore = models_data[model_name]['iscore']
    
    axes[idx].scatter(caption_lengths, iscore, alpha=0.6, s=50, edgecolors='black', linewidth=0.5)
    
    # L√≠nea de regresi√≥n
    z = np.polyfit(caption_lengths, iscore, 1)
    p = np.poly1d(z)
    axes[idx].plot(caption_lengths, p(caption_lengths), "r--", alpha=0.8, linewidth=2, label='Regresi√≥n lineal')
    
    corr = df_correlations[df_correlations['Modelo'] == model_name]['Correlaci√≥n IScore-Caption'].values[0]
    axes[idx].set_xlabel('Caption Length (caracteres)', fontsize=12)
    axes[idx].set_ylabel('IScore', fontsize=12)
    axes[idx].set_title(f'{model_name}\nIScore vs Caption Length\n(r={corr:.3f})', 
                        fontsize=13, fontweight='bold')
    axes[idx].grid(True, alpha=0.3)
    axes[idx].legend()

plt.suptitle('Relaci√≥n entre IScore y Longitud del Caption', fontsize=16, fontweight='bold', y=0.995)
plt.tight_layout()
caption_corr_path = Path(OUTPUT_DIR) / "scatter_caption_length_vs_iscore.png"
plt.savefig(caption_corr_path, dpi=300, bbox_inches='tight')
print(f"üíæ Gr√°fica guardada en: {caption_corr_path}")
plt.show()

# %% [markdown]
# ## 6Ô∏è‚É£ Visualizaciones para Presentaci√≥n

# %% [markdown]
# ### 6.1 Dashboard Comparativo Completo

# %%
fig = plt.figure(figsize=(20, 12))
gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

# 1. Boxplot IScore (arriba izquierda)
ax1 = fig.add_subplot(gs[0, 0])
bp = ax1.boxplot(iscore_data, labels=model_names, patch_artist=True)
ax1.axhline(y=0.5, color='r', linestyle='--', linewidth=2)
ax1.set_title('Distribuci√≥n IScore', fontweight='bold')
ax1.set_ylabel('IScore')
ax1.grid(True, alpha=0.3)
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)
    patch.set_alpha(0.7)

# 2. Boxplot TScore (arriba centro)
ax2 = fig.add_subplot(gs[0, 1])
bp = ax2.boxplot(tscore_data, labels=model_names, patch_artist=True)
ax2.axhline(y=0.5, color='r', linestyle='--', linewidth=2)
ax2.set_title('Distribuci√≥n TScore', fontweight='bold')
ax2.set_ylabel('TScore')
ax2.grid(True, alpha=0.3)
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)
    patch.set_alpha(0.7)

# 3. Balance Score (arriba derecha)
ax3 = fig.add_subplot(gs[0, 2])
x_pos = np.arange(len(model_names))
bars = ax3.barh(x_pos, df_balance['Balance Score (Media)'], color=colors[:len(model_names)])
ax3.set_yticks(x_pos)
ax3.set_yticklabels(df_balance['Modelo'])
ax3.set_xlabel('Balance Score')
ax3.set_title('Balance Multimodal', fontweight='bold')
ax3.axvline(x=1.0, color='r', linestyle='--', linewidth=2)
ax3.grid(True, alpha=0.3, axis='x')

# 4. Scatter IScore vs TScore combinado (centro izquierda)
ax4 = fig.add_subplot(gs[1, 0])
for model_name, color in zip(model_names, colors):
    iscore = models_data[model_name]['iscore']
    tscore = models_data[model_name]['tscore']
    ax4.scatter(iscore, tscore, alpha=0.5, s=30, label=model_name, color=color)
ax4.plot([0, 1], [1, 0], 'r--', linewidth=2, label='Balance ideal')
ax4.set_xlabel('IScore')
ax4.set_ylabel('TScore')
ax4.set_title('IScore vs TScore (Todos los modelos)', fontweight='bold')
ax4.legend(fontsize=8)
ax4.grid(True, alpha=0.3)
ax4.set_xlim(0, 1)
ax4.set_ylim(0, 1)

# 5. Heatmap de correlaciones (centro)
ax5 = fig.add_subplot(gs[1, 1])
sns.heatmap(
    correlation_matrix,
    annot=True,
    fmt='.2f',
    cmap='coolwarm',
    center=0,
    square=True,
    xticklabels=model_names,
    yticklabels=model_names,
    cbar_kws={'label': 'Correlaci√≥n'},
    ax=ax5,
    linewidths=0.5
)
ax5.set_title('Correlaci√≥n entre Modelos', fontweight='bold')

# 6. Caption Length vs IScore (centro derecha)
ax6 = fig.add_subplot(gs[1, 2])
for model_name, color in zip(model_names, colors):
    iscore = models_data[model_name]['iscore']
    ax6.scatter(caption_lengths, iscore, alpha=0.4, s=20, label=model_name, color=color)
ax6.set_xlabel('Caption Length')
ax6.set_ylabel('IScore')
ax6.set_title('IScore vs Caption Length', fontweight='bold')
ax6.legend(fontsize=8)
ax6.grid(True, alpha=0.3)

# 7. Tabla de estad√≠sticas (abajo izquierda)
ax7 = fig.add_subplot(gs[2, :])
ax7.axis('tight')
ax7.axis('off')
table_data = df_balance[['Modelo', 'Balance Score (Media)', 'Muestras Balanceadas (%)']].values
table = ax7.table(cellText=table_data, colLabels=['Modelo', 'Balance Score', 'Muestras Balanceadas (%)'],
                  cellLoc='center', loc='center', bbox=[0, 0, 1, 1])
table.auto_set_font_size(False)
table.set_fontsize(10)
table.scale(1, 2)
ax7.set_title('Resumen de M√©tricas de Balance', fontweight='bold', pad=20)

plt.suptitle('Dashboard Comparativo: An√°lisis de Balance Multimodal en Modelos CLIP M√©dicos',
             fontsize=18, fontweight='bold', y=0.98)

dashboard_path = Path(OUTPUT_DIR) / "dashboard_completo.png"
plt.savefig(dashboard_path, dpi=300, bbox_inches='tight')
print(f"üíæ Dashboard guardado en: {dashboard_path}")
plt.show()

# %% [markdown]
# ### 6.2 Ranking de Modelos por Balance

# %%
fig, ax = plt.subplots(figsize=(12, 8))

# Ordenar por Balance Score
df_sorted = df_balance.sort_values('Balance Score (Media)', ascending=True)

y_pos = np.arange(len(model_names))
bars = ax.barh(y_pos, df_sorted['Balance Score (Media)'], 
               color=plt.cm.viridis(np.linspace(0, 1, len(model_names))))

ax.set_yticks(y_pos)
ax.set_yticklabels(df_sorted['Modelo'])
ax.set_xlabel('Balance Score (Media)', fontsize=14, fontweight='bold')
ax.set_title('Ranking de Modelos por Balance Multimodal\n(Mayor = M√°s Balanceado)', 
             fontsize=16, fontweight='bold', pad=20)
ax.axvline(x=1.0, color='r', linestyle='--', linewidth=2, label='Balance perfecto (1.0)')
ax.grid(True, alpha=0.3, axis='x')
ax.legend(fontsize=12)

# Agregar valores y porcentaje de muestras balanceadas
for i, (bar, value, pct) in enumerate(zip(bars, 
                                          df_sorted['Balance Score (Media)'],
                                          df_sorted['Muestras Balanceadas (%)'])):
    ax.text(value + 0.01, i, f'{value:.3f}\n({pct:.1f}% balanceadas)', 
            va='center', fontweight='bold', fontsize=10)

plt.tight_layout()
ranking_path = Path(OUTPUT_DIR) / "ranking_balance_modelos.png"
plt.savefig(ranking_path, dpi=300, bbox_inches='tight')
print(f"üíæ Gr√°fica guardada en: {ranking_path}")
plt.show()

# %% [markdown]
# ## üìã Resumen Final

# %%
print("="*80)
print("‚úÖ AN√ÅLISIS COMPLETADO")
print("="*80)
print(f"\nüìä Total de muestras analizadas: {len(df)}")
print(f"ü§ñ Modelos analizados: {len(model_names)}")
print(f"üìÅ Archivos generados en: {OUTPUT_DIR}")
print("\nüìã Archivos creados:")
print(f"   ‚Ä¢ estadisticas_descriptivas.csv")
print(f"   ‚Ä¢ metricas_balance_multimodal.csv")
print(f"   ‚Ä¢ analisis_estadisticos_inferenciales.csv")
print(f"   ‚Ä¢ correlaciones_caption_length.csv")
print(f"   ‚Ä¢ boxplots_iscore_tscore.png")
print(f"   ‚Ä¢ violinplots_iscore_tscore.png")
print(f"   ‚Ä¢ scatter_iscore_vs_tscore.png")
print(f"   ‚Ä¢ heatmap_correlaciones.png")
print(f"   ‚Ä¢ balance_score_comparison.png")
print(f"   ‚Ä¢ scatter_caption_length_vs_iscore.png")
print(f"   ‚Ä¢ dashboard_completo.png")
print(f"   ‚Ä¢ ranking_balance_modelos.png")
print("\nüéâ ¬°An√°lisis completo! Revisa los archivos generados.")

# %% [markdown]
# ---
#
# **Proyecto de tesis: Medici√≥n del balance multimodal con SHAP en modelos CLIP m√©dicos**

