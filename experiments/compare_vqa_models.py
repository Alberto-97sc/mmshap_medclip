# ---
# jupyter:
#   jupytext:
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
#       jupytext_version: 1.17.3
#   kernelspec:
#     display_name: Python 3
#     name: python3
# ---

# %% [markdown]
# # üî¨ An√°lisis SHAP de Modelos CLIP M√©dicos en VQA-Med 2019
#
# Este notebook permite ejecutar SHAP en una misma muestra VQA con PubMedCLIP y BiomedCLIP
# y generar heatmaps individuales detallados para cada uno, permitiendo comparar su comportamiento.
#
# **Modelos:**
# - PubMedCLIP
# - BioMedCLIP
#
# **Dataset:** VQA-Med 2019
#
# **Tarea:** VQA (Visual Question Answering)
#
# **Visualizaci√≥n:** Heatmaps individuales con imagen y pregunta por cada modelo
#
# ---

# %% [markdown]
# ## üì¶ Configuraci√≥n inicial

# %%
import os
from pathlib import Path

# üìå Configuraci√≥n - Asegurar que estamos en el directorio correcto
try:
    # En scripts Python
    PROJECT_ROOT = Path(__file__).parent.parent
except NameError:
    # En notebooks de Jupyter
    PROJECT_ROOT = Path.cwd()
    # Si estamos en experiments/, subir un nivel
    if PROJECT_ROOT.name == "experiments":
        PROJECT_ROOT = PROJECT_ROOT.parent

os.chdir(PROJECT_ROOT)
print(f"üìÇ Directorio de trabajo: {PROJECT_ROOT}")

# %% [markdown]
# ## üéØ Cargar dataset y dispositivo

# %%
from mmshap_medclip.io_utils import load_config
from mmshap_medclip.devices import get_device
from mmshap_medclip.registry import build_dataset

print("üîÑ Cargando configuraci√≥n y dataset...")
# Nota: Necesitar√°s crear un archivo de configuraci√≥n para VQA-Med 2019
# Por ahora, cargamos directamente el dataset
device = get_device()

# Construir dataset VQA-Med 2019 directamente
# Ajusta estos par√°metros seg√∫n tu configuraci√≥n
dataset_params = {
    "zip_path": "data/VQA-Med-2019.zip",  # Ruta al ZIP padre que contiene Training.zip
    "split": "Training",  # SOLO se soporta "Training" o "train"
    "images_subdir": "Train_images",  # SOLO se soporta "Train_images" para el split Training
    "n_rows": "all"  # o un n√∫mero para limitar muestras (ej: 100)
}

from mmshap_medclip.registry import build_dataset
dataset = build_dataset({"name": "vqa_med_2019", "params": dataset_params})

print(f"‚úÖ Dataset cargado: {len(dataset)} muestras")
print(f"üíª Dispositivo: {device}")

# %% [markdown]
# ## ü§ñ Cargar los modelos VQA (PubMedCLIP y BiomedCLIP)

# %%
from mmshap_medclip.comparison_vqa import load_vqa_models

models = load_vqa_models(device)

# Filtrar solo los modelos que se cargaron correctamente
loaded_models = {k: v for k, v in models.items() if v is not None}
print(f"\nüìä Modelos cargados: {len(loaded_models)}/{len(models)}")

# %% [markdown]
# ## üöÄ Ejecutar SHAP y visualizar resultados
#
# Este bloque ejecuta SHAP en todos los modelos y muestra los heatmaps.

# %%
from mmshap_medclip.comparison_vqa import (
    run_vqa_shap_on_models,
    print_vqa_summary,
    plot_vqa_comparison
)

# üéØ CONFIGURACI√ìN: Cambiar este n√∫mero para probar diferentes muestras
MUESTRA_A_ANALIZAR = 0

# Ejecutar SHAP en todos los modelos
print("="*80)
print("üöÄ INICIANDO AN√ÅLISIS COMPARATIVO VQA")
print("="*80)

results, image, question, answer, candidates, category = run_vqa_shap_on_models(
    models=loaded_models,
    sample_idx=MUESTRA_A_ANALIZAR,
    dataset=dataset,
    device=device,
    target_logit="correct",  # o "predicted"
    verbose=True
)

# Imprimir informaci√≥n de la muestra
print("\n" + "="*80)
print("üìù Informaci√≥n de la muestra:")
print(f"   Pregunta: {question}")
print(f"   Categor√≠a: {category}")
print(f"   Respuesta correcta: {answer}")
print(f"   Candidatos: {len(candidates)} opciones")
print("="*80 + "\n")

# Mostrar resumen en tabla
print_vqa_summary(results)

# Visualizar comparaci√≥n
print("\n" + "="*80)
print("üîç GENERANDO VISUALIZACI√ìN COMPARATIVA")
print("="*80 + "\n")

fig = plot_vqa_comparison(
    results, image, question, answer, candidates, MUESTRA_A_ANALIZAR
)
if fig is not None:
    fig.show()

# %% [markdown]
# ## üîç Heatmaps individuales detallados

# %%
from mmshap_medclip.tasks.vqa import plot_vqa

# Generar heatmaps individuales para cada modelo
for model_name, result in results.items():
    if result is None:
        continue
    
    print(f"\n{'='*60}")
    print(f"üîç Heatmap detallado: {model_name}")
    print(f"{'='*60}\n")
    
    try:
        fig = plot_vqa(
            image=image,
            question=question,
            vqa_output=result,
            model_wrapper=result.get("model_wrapper"),
            display_plot=True
        )
        
        # Imprimir m√©tricas
        prediction = result.get('prediction', 'N/A')
        correct = result.get('correct', None)
        tscore = result.get('tscore', 0.0)
        iscore = result.get('iscore', 0.0)
        correct_str = "‚úÖ" if correct else "‚ùå" if correct is False else "?"
        print(f"üìä {model_name} - Predicci√≥n: {prediction} {correct_str} | TScore: {tscore:.2%} | IScore: {iscore:.2%}\n")
        
    except Exception as e:
        print(f"‚ùå Error generando heatmap para {model_name}: {e}\n")

# %% [markdown]
# ## üíæ Guardar resultados
#
# Descomentar para guardar los resultados en disco.

# %%
from pathlib import Path
import json

# Descomentar para guardar
# output_dir = Path("outputs/vqa")
# output_dir.mkdir(parents=True, exist_ok=True)
# 
# # Guardar figura
# if fig is not None:
#     fig_path = output_dir / f"vqa_comparison_sample_{MUESTRA_A_ANALIZAR}.png"
#     fig.savefig(fig_path, dpi=150, bbox_inches='tight')
#     print(f"üíæ Figura guardada en: {fig_path}")
#     plt.close(fig)
# 
# # Guardar resultados num√©ricos
# summary = {}
# for model_name, result in results.items():
#     if result is not None:
#         summary[model_name] = {
#             "prediction": result.get('prediction', 'N/A'),
#             "correct": result.get('correct', None),
#             "tscore": float(result.get('tscore', 0.0)),
#             "iscore": float(result.get('iscore', 0.0)),
#         }
# 
# json_path = output_dir / f"vqa_comparison_sample_{MUESTRA_A_ANALIZAR}.json"
# with open(json_path, 'w') as f:
#     json.dump({
#         "sample_idx": MUESTRA_A_ANALIZAR,
#         "question": question,
#         "answer": answer,
#         "category": category,
#         "candidates": candidates,
#         "results": summary
#     }, f, indent=2)
# 
# print(f"üíæ Resultados guardados en: {json_path}")

# %% [markdown]
# ## üî¨ An√°lisis de m√∫ltiples muestras
#
# Para analizar m√∫ltiples muestras y obtener estad√≠sticas agregadas,
# descomentar y ejecutar la siguiente celda.

# %%
# from mmshap_medclip.comparison_vqa import run_vqa_shap_on_models
# import pandas as pd
# 
# # Ejemplo: analizar 5 muestras
# sample_indices = [0, 10, 20, 30, 40]
# all_results = []
# 
# for idx in sample_indices:
#     print(f"\nüìç Procesando muestra {idx}...")
#     results, _, question, answer, candidates, category = run_vqa_shap_on_models(
#         models=loaded_models,
#         sample_idx=idx,
#         dataset=dataset,
#         device=device,
#         target_logit="correct",
#         verbose=False
#     )
#     
#     for model_name, result in results.items():
#         if result is not None:
#             all_results.append({
#                 "sample_idx": idx,
#                 "model": model_name,
#                 "prediction": result.get('prediction', 'N/A'),
#                 "correct": result.get('correct', None),
#                 "tscore": result.get('tscore', 0.0),
#                 "iscore": result.get('iscore', 0.0),
#                 "category": category,
#                 "question": question[:50] + "..."
#             })
# 
# df_results = pd.DataFrame(all_results)
# print("\nüìä Primeras filas del DataFrame de resultados:")
# print(df_results.head(10))
# 
# # Estad√≠sticas por modelo
# if not df_results.empty:
#     print("\nüìà Estad√≠sticas por modelo:")
#     print(df_results.groupby('model')[['tscore', 'iscore']].mean().round(4))
#     
#     # Precisi√≥n por modelo
#     print("\nüéØ Precisi√≥n por modelo:")
#     for model_name in df_results['model'].unique():
#         model_df = df_results[df_results['model'] == model_name]
#         correct_count = model_df['correct'].sum()
#         total = len(model_df)
#         accuracy = correct_count / total if total > 0 else 0.0
#         print(f"   {model_name}: {accuracy:.2%} ({correct_count}/{total})")

# %% [markdown]
# ---
#
# ## üìù Notas de Uso
#
# ### üéØ Uso B√°sico
#
# 1. **Configurar ruta del dataset:**
#    Modifica `dataset_params["zip_path"]` con la ruta correcta al archivo ZIP de VQA-Med 2019.
#
# 2. **Cambiar la muestra a analizar:**
#    Modifica la variable `MUESTRA_A_ANALIZAR` en la celda correspondiente.
#
# 3. **Re-ejecutar el an√°lisis:**
#    Simplemente ejecuta las celdas de nuevo con el nuevo n√∫mero de muestra.
#
# 4. **Ver resultados:**
#    - Heatmaps individuales detallados para cada modelo
#    - Resumen de m√©tricas en tabla
#    - An√°lisis de balance multimodal
#
# ### üìä M√©tricas Explicadas
#
# - **Predicci√≥n**: Candidato predicho por el modelo
# - **Correcto**: Si la predicci√≥n coincide con la respuesta correcta
# - **TScore**: Proporci√≥n de importancia asignada al texto (0-100%)
# - **IScore**: Proporci√≥n de importancia asignada a la imagen (0-100%)
# - **Balance ideal**: TScore ‚âà IScore ‚âà 50%
#
# ### üî¨ Funciones Disponibles
#
# - `load_vqa_models()`: Carga PubMedCLIP y BiomedCLIP
# - `run_vqa_shap_on_models()`: Ejecuta VQA+SHAP en todos los modelos
# - `plot_vqa_comparison()`: Muestra comparaci√≥n visual de modelos
# - `print_vqa_summary()`: Imprime resumen comparativo en tabla
# - `plot_vqa()`: Genera heatmap individual detallado
#
# ### ‚öôÔ∏è Par√°metros Importantes
#
# - `target_logit`: "correct" (explicar logit del candidato correcto) o "predicted" (explicar logit del predicho)
# - SHAP solo se aplica a imagen y pregunta, NO a los candidatos
#
# ---
#
# **Proyecto de tesis sobre balance multimodal en modelos CLIP m√©dicos aplicados a VQA**

